services:
  db:
    image: postgres:latest
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - ./postgres_data:/var/lib/postgresql/data

  minio:
    image: minio/minio:latest
    command: server --console-address ":9001" /data
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console UI
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - ./minio_data:/data

  mlflow:
    build:
      context: ./mlflow
      dockerfile: Dockerfile
    environment:
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_REGION: ${AWS_REGION}
    depends_on:
      - db
      - minio
    ports:
      - "${MLFLOW_PORT}:${MLFLOW_PORT}"

    # No need to mount code, just logs artifacts to S3/Minio

    command: >
      mlflow server
      --backend-store-uri ${MLFLOW_TRACKING_URI}
      --default-artifact-root ${MLFLOW_ARTIFACT_ROOT}
      --serve-artifacts
      --artifacts-destination ${MLFLOW_ARTIFACT_ROOT}
      --host 0.0.0.0
      --port ${MLFLOW_PORT}

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    depends_on:
      - mlflow
      - minio
      - db
    environment:
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT}
      AWS_REGION: ${AWS_REGION}
    # You can override entrypoint/command to run your training script here
    # command: python src/test.py
    volumes:
      - ./client/src:/app/src
    command: tail -f /dev/null